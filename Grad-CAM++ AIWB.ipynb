{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Code for Grad-CAM++ is explained below:**\n",
    "\n",
    "\n",
    "\n",
    "**Step 1:**\n",
    "Firstly we will import the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Step 2:**\n",
    "Now we will define the Grad-CAM function which we will require later in the Grad-CAM++ part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grad-CAM++ funtion there are four parameters which are\n",
    "\n",
    "1) input_model which we are using to import our pre-trained model.\n",
    "\n",
    "2) The second parameter is the image that is the input image image for which we want to perform the localization.\n",
    "\n",
    "3) The third parameter is the layer name which we are using to input the layer from the user i.e by considering which layer as the penultimate layer do we wnat to perform the localization.\n",
    "\n",
    "4) The fourth and the fifth parameters are the Height and the Width of the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function is used to calculate the maximum pixel values along the particular row/column of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**\n",
    "Now we will define the normalize function which we are using to normalize the tensor by its L2 form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:**\n",
    "The next step is to visualize the input saliency.\n",
    "\n",
    "**What is Saliency?**\n",
    "\n",
    "The idea behind saliency is pretty simple in hindsight. We compute the gradient of output category with respect to input image.\n",
    "\n",
    "![alt text](saliency.png \"Title\")\n",
    "\n",
    "This should tell us how the output value changes with respect to a small change in inputs. We can use these gradients to highlight input regions that cause the most change in the output. Intuitively this should highlight salient image regions that most contribute towards the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet the saliency of the image is calculated and the output is stored in the output,grads_val variables.\n",
    "\n",
    "The two variables will give us the loss and the gradient value w.r.t to the input image which will help us to analyze which part of the image has the most postive effect on the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:**\n",
    "\n",
    "The Next step is to perform the Global Average Pooling which is the core concept used in Grad-CAM.For performing the above step we are taking the mean of the gradients that we obtained in the earlier step.\n",
    "\n",
    "In the next part we specify the parts of the image that we want to zoom to make localization simpler.The scipy package has a zoom function for particularly focusing on the specific part of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference between the Grad-CAM and the Grad-CAM++ part is that in Grad-CAM we are we take the global average pooling for each layer in Grad-CAM++ which is not the case in Grad-CAM.\n",
    "\n",
    "So in Grad-CAM++ we will calculate the gradients of each layer and store the value in the variables named first,second and third.\n",
    "\n",
    "\n",
    "**Step 6**\n",
    "In the last part we can see that the Grad-CAM is not able to properly localize cancer part which is not the case with Grad-CAM++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imorting the rquired libraries the libraries\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import numpy as np\n",
    "from keras.backend import tensorflow_backend\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "#defining the Grad-CAM function\n",
    "def grad_cam(input_model, image, layer_name,H=224,W=224):\n",
    "    \n",
    "    #Calculates the maximum pixel value along a particular row/column of an image\n",
    "    \n",
    "    cls = np.argmax(input_model.predict(image))\n",
    "    \n",
    "    def normalize(x):\n",
    "        #Utility function to normalize a tensor by its L2 norm\n",
    "        return (x + 1e-10) / (K.sqrt(K.mean(K.square(x))) + 1e-10)\n",
    "    \n",
    "    \n",
    "    #GradCAM method for visualizing input saliency. \n",
    "    y_c = input_model.output[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    \n",
    "    #compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "    \n",
    "    #this function returns the loss and grads given the input picture\n",
    "    gradient_function = K.function([input_model.input], [conv_output, grads])\n",
    "    \n",
    "    #gradient function returns the loss and grads given the input picture\n",
    "    output, grads_val = gradient_function([image])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    \n",
    "    #Calculate the means of the gradient for Global Average Pooling.\n",
    "    weights = np.mean(grads_val, axis=(0, 1))\n",
    "    \n",
    "    #Calculating the dot/scalar product and storing it in the variable cam.\n",
    "    cam = np.dot(output, weights)\n",
    "    \n",
    "    #Element-wise maximum of two arrays.\n",
    "    cam = np.maximum(cam, 0)\n",
    "    \n",
    "    #The Zoom function will zoom the image according to the parameters specified in the function.\n",
    "    cam = zoom(cam,H/cam.shape[0])\n",
    "   \n",
    "    #Used for scaling from 0 to 1\n",
    "    cam = cam / cam.max()\n",
    "    \n",
    "    return cam\n",
    "\n",
    "def grad_cam_plus(input_model, img, layer_name,H=224,W=224):\n",
    "    \n",
    "    \n",
    "    #Calculates the maximum pixel value along a particular row/column of an image\n",
    "    cls = np.argmax(input_model.predict(img))\n",
    "    y_c = input_model.output[0, cls]\n",
    "    conv_output = input_model.get_layer(layer_name).output\n",
    "    \n",
    "     #compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(y_c, conv_output)[0]\n",
    "  \n",
    "    #Calculating the gradients of the three layers.\n",
    "    first = K.exp(y_c)*grads\n",
    "    second = K.exp(y_c)*grads*grads\n",
    "    third = K.exp(y_c)*grads*grads*grads\n",
    "\n",
    "    #this function returns the loss and grads given the input picture\n",
    "    gradient_function = K.function([input_model.input], [y_c,first,second,third, conv_output, grads])\n",
    "    y_c, conv_first_grad, conv_second_grad,conv_third_grad, conv_output, grads_val = gradient_function([img])\n",
    "    \n",
    "    #Calculating the global sum for the use in GAP(Global Average Pooling)\n",
    "    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n",
    "\n",
    "    #Calculating the weights of the kth feature map for class c.\n",
    "    alpha_num = conv_second_grad[0]\n",
    "    alpha_denom = conv_second_grad[0]*2.0 + conv_third_grad[0]*global_sum.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n",
    "    alphas = alpha_num/alpha_denom\n",
    "\n",
    "    weights = np.maximum(conv_first_grad[0], 0.0)\n",
    "\n",
    "    alpha_normalization_constant = np.sum(np.sum(alphas, axis=0),axis=0)\n",
    "\n",
    "    alphas /= alpha_normalization_constant.reshape((1,1,conv_first_grad[0].shape[2]))\n",
    "\n",
    "    deep_linearization_weights = np.sum((weights*alphas).reshape((-1,conv_first_grad[0].shape[2])),axis=0)\n",
    "    #print deep_linearization_weights\n",
    "    grad_CAM_map = np.sum(deep_linearization_weights*conv_output[0], axis=2)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Passing through ReLU to include only the positive features that influence the image.\n",
    "    cam = np.maximum(grad_CAM_map, 0)\n",
    "    cam = zoom(cam,H/cam.shape[0])\n",
    "    cam = cam / np.max(cam) # scale 0 to 1.0    \n",
    "    \n",
    "\n",
    "    return cam\n",
    "\n",
    "\n",
    "\n",
    "#Code for superimposing the activation map on the original image\n",
    "img1=cv2.resize(cv2.imread(\"input.png\"),(224,224),interpolation = cv2.INTER_NEAREST)\n",
    "gradcam=cv2.resize(cv2.imread('g_c_plus.png'),(224,224),interpolation = cv2.INTER_NEAREST)\n",
    "img = (gradcam*0.25)+img1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](final_out.png \"Output of Grad-CAM and Grad-CAM++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Activation Maps Superimposed on original image of Grad-CAM is as shown below\n",
    "\n",
    "\n",
    "![alt text](g_c_s.png \"Superimposed activation map on Grad-CAM\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Activation Maps Superimposed on original image of Grad-CAM++ is as shown below\n",
    "\n",
    "![alt text](g_c_s.png \"Superimposed activation map on Grad-CAM++\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
